{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- V1 : LGBM STACKING \n",
    "- V2 : LGBM, MLP16 STACKING\n",
    "- V3 : V2 + pred 5 score 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from sklearn import svm, neighbors, linear_model, neural_network\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, QuantileTransformer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.decomposition import PCA, TruncatedSVD, KernelPCA\n",
    "\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm, neighbors, linear_model\n",
    "import gc\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import Matern, RationalQuadratic\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.decomposition import FastICA, TruncatedSVD, PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cat\n",
    "\n",
    "from tqdm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.7 s, sys: 4.58 s, total: 26.3 s\n",
      "Wall time: 26.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df = pd.read_csv('../input/train.csv')\n",
    "test_df = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_columns = [c for c in train_df.columns if c not in ['id','target','wheezy-copper-turtle-magic']]\n",
    "\n",
    "magic_variance_over2 = {}\n",
    "for magic in sorted(train_df['wheezy-copper-turtle-magic'].unique()):\n",
    "    temp = train_df.loc[train_df['wheezy-copper-turtle-magic']==magic]\n",
    "    std = temp[train_columns].std()\n",
    "    magic_variance_over2[magic] = list(std.index.values[np.where(std >2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hist_model(object):\n",
    "    \n",
    "    def __init__(self, bins=50):\n",
    "        self.bins = bins\n",
    "        \n",
    "    def fit(self, X):\n",
    "        \n",
    "        bin_hight, bin_edge = [], []\n",
    "        \n",
    "        for var in X.T:\n",
    "            # get bins hight and interval\n",
    "            bh, bedge = np.histogram(var, bins=self.bins)\n",
    "            bin_hight.append(bh)\n",
    "            bin_edge.append(bedge)\n",
    "        \n",
    "        self.bin_hight = np.array(bin_hight)\n",
    "        self.bin_edge = np.array(bin_edge)\n",
    "   \n",
    "\n",
    "    def predict(self, X):\n",
    "        \n",
    "        scores = []\n",
    "        for obs in X:\n",
    "            obs_score = []\n",
    "            for i, var in enumerate(obs):\n",
    "                # find wich bin obs is in\n",
    "                bin_num = (var > self.bin_edge[i]).argmin()-1\n",
    "                obs_score.append(self.bin_hight[i, bin_num]) # find bin hitght\n",
    "            \n",
    "            scores.append(np.mean(obs_score))\n",
    "        \n",
    "        return np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Lasso, LassoLars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "debug = True\n",
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svnu_params = {'probability':True, 'kernel':'poly','degree':4,'gamma':'auto','nu':0.4,'coef0':0.08, 'random_state':4}\n",
    "svnu2_params = {'probability':True, 'kernel':'poly','degree':2,'gamma':'auto','nu':0.4,'coef0':0.08, 'random_state':4}\n",
    "svc_params = {'probability':True,'kernel':'poly','degree':4,'gamma':'auto', 'random_state':4}\n",
    "lr_params = {'solver':'liblinear','penalty':'l1','C':0.05,'n_jobs':-1, 'random_state':42}\n",
    "mlp16_params = {'activation':'relu','solver':'lbfgs','tol':1e-06, 'hidden_layer_sizes':(16, ), 'random_state':42}\n",
    "mlp128_params = {'activation':'relu','solver':'lbfgs','tol':1e-06, 'hidden_layer_sizes':(128, ), 'random_state':42}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oofs(random_state):\n",
    "    oof_nusvc = np.zeros(len(train_df))\n",
    "    preds_nusvc = np.zeros(len(test_df))\n",
    "\n",
    "    oof_nusvc2 = np.zeros(len(train_df))\n",
    "    preds_nusvc2 = np.zeros(len(test_df))\n",
    "\n",
    "    oof_qda = np.zeros(len(train_df))\n",
    "    preds_qda = np.zeros(len(test_df))\n",
    "\n",
    "    oof_svc = np.zeros(len(train_df))\n",
    "    preds_svc = np.zeros(len(test_df))\n",
    "    \n",
    "    oof_knn = np.zeros(len(train_df))\n",
    "    preds_knn = np.zeros(len(test_df))\n",
    "    \n",
    "    oof_lr = np.zeros(len(train_df))\n",
    "    preds_lr = np.zeros(len(test_df))\n",
    "    \n",
    "    cols = [c for c in train_df.columns if c not in ['id', 'target', 'wheezy-copper-turtle-magic']]\n",
    "\n",
    "    for i in tqdm_notebook(range(512)):\n",
    "\n",
    "        # each magic\n",
    "        train = train_df[train_df['wheezy-copper-turtle-magic'] == i]\n",
    "        test = test_df[test_df['wheezy-copper-turtle-magic'] == i]\n",
    "\n",
    "        # for oof\n",
    "        train_idx_origin = train.index\n",
    "        test_idx_origin = test.index\n",
    "\n",
    "\n",
    "        # start point\n",
    "\n",
    "        # new cols\n",
    "        cols = magic_variance_over2[i]\n",
    "\n",
    "        X_train = train.reset_index(drop=True)[cols].values\n",
    "        y_train = train.reset_index(drop=True).target\n",
    "\n",
    "        X_test = test[cols].values\n",
    "\n",
    "        # vstack\n",
    "        data = np.vstack([X_train, X_test])\n",
    "        \n",
    "        # PCA\n",
    "        data = KernelPCA(n_components=len(cols), kernel='cosine', random_state=random_state).fit_transform(data)\n",
    "        \n",
    "        # Bad\n",
    "        '''\n",
    "        gmm_pred = np.zeros((len(data), 5))\n",
    "        for j in range(5):\n",
    "            gmm = GMM(n_components=4, random_state=random_state + j, max_iter=1000).fit(data)\n",
    "            gmm_pred[:, j] += gmm.predict(data)\n",
    "        '''\n",
    "          \n",
    "        # original\n",
    "        gmm = GMM(n_components=5, random_state=random_state, max_iter=1000).fit(data)\n",
    "        gmm_pred = gmm.predict_proba(data)\n",
    "        gmm_score = gmm.score_samples(data)\n",
    "        gmm_label = gmm.predict(data)\n",
    "        \n",
    "        hist = hist_model(); hist.fit(data)\n",
    "        hist_pred = hist.predict(data).reshape(-1, 1)\n",
    "\n",
    "        data = np.hstack([data, gmm_pred])\n",
    "\n",
    "        # HOXI\n",
    "        data = np.hstack([data, gmm_pred])\n",
    "        data = np.hstack([data, gmm_pred])\n",
    "        data = np.hstack([data, gmm_pred])\n",
    "        \n",
    "        # Add Some Features\n",
    "        data = np.hstack([data, gmm_pred])\n",
    "        data = np.hstack([data, hist_pred, gmm_score.reshape(-1, 1)])\n",
    "        data = np.hstack([data, gmm_score.reshape(-1, 1)])\n",
    "        data = np.hstack([data, gmm_score.reshape(-1, 1)])\n",
    "\n",
    "        # STANDARD SCALER\n",
    "        data = StandardScaler().fit_transform(data)\n",
    "\n",
    "        # new train/test\n",
    "        X_train = data[:X_train.shape[0]]\n",
    "        X_test = data[X_train.shape[0]:]\n",
    "\n",
    "        fold = StratifiedKFold(n_splits=5, random_state=random_state)\n",
    "        for tr_idx, val_idx in fold.split(X_train, gmm_label[:X_train.shape[0]]):\n",
    "            \n",
    "            # NuSVC 1\n",
    "            clf = svm.NuSVC(**svnu_params)\n",
    "            clf.fit(X_train[tr_idx], y_train[tr_idx])\n",
    "            oof_nusvc[train_idx_origin[val_idx]] = clf.predict_proba(X_train[val_idx])[:,1]\n",
    "            preds_nusvc[test_idx_origin] += clf.predict_proba(X_test)[:,1] / fold.n_splits\n",
    "\n",
    "            # NuSVC 2\n",
    "            clf = svm.NuSVC(**svnu2_params)\n",
    "            clf.fit(X_train[tr_idx], y_train[tr_idx])\n",
    "            oof_nusvc2[train_idx_origin[val_idx]] = clf.predict_proba(X_train[val_idx])[:,1]\n",
    "            preds_nusvc2[test_idx_origin] += clf.predict_proba(X_test)[:,1] / fold.n_splits\n",
    "\n",
    "\n",
    "            # qda 3\n",
    "            clf = QuadraticDiscriminantAnalysis(reg_param=0.111)\n",
    "            clf.fit(X_train[tr_idx], y_train[tr_idx])\n",
    "            oof_qda[train_idx_origin[val_idx]] = clf.predict_proba(X_train[val_idx])[:,1]\n",
    "            preds_qda[test_idx_origin] += clf.predict_proba(X_test)[:,1] / fold.n_splits\n",
    "\n",
    "            # SVC 4\n",
    "            clf = svm.SVC(**svc_params)\n",
    "            clf.fit(X_train[tr_idx], y_train[tr_idx])\n",
    "            oof_svc[train_idx_origin[val_idx]] = clf.predict_proba(X_train[val_idx])[:,1]\n",
    "            preds_svc[test_idx_origin] += clf.predict_proba(X_test)[:,1] / fold.n_splits\n",
    "            \n",
    "            # knn 8\n",
    "            clf = KNeighborsClassifier(n_neighbors=16)\n",
    "            clf.fit(X_train[tr_idx], y_train[tr_idx])\n",
    "            oof_knn[train_idx_origin[val_idx]] = clf.predict_proba(X_train[val_idx])[:,1]\n",
    "            preds_knn[test_idx_origin] += clf.predict_proba(X_test)[:,1] / fold.n_splits   \n",
    "            \n",
    "            # LR 5\n",
    "            clf = linear_model.LogisticRegression(**lr_params)\n",
    "            clf.fit(X_train[tr_idx], y_train[tr_idx])\n",
    "            oof_lr[train_idx_origin[val_idx]] = clf.predict_proba(X_train[val_idx])[:,1]\n",
    "            preds_lr[test_idx_origin] += clf.predict_proba(X_test)[:,1] / fold.n_splits\n",
    "            \n",
    "    oof_train = pd.DataFrame()\n",
    "\n",
    "    oof_train['nusvc'] = oof_nusvc\n",
    "    oof_train['nusvc2'] = oof_nusvc2\n",
    "    oof_train['qda'] = oof_qda\n",
    "    oof_train['svc'] = oof_svc\n",
    "    oof_train['knn'] = oof_knn\n",
    "    oof_train['lr'] = oof_lr\n",
    "    \n",
    "    oof_test = pd.DataFrame()\n",
    "\n",
    "    oof_test['nusvc'] = preds_nusvc\n",
    "    oof_test['nusvc2'] = preds_nusvc2\n",
    "    oof_test['qda'] = preds_qda\n",
    "    oof_test['svc'] = preds_svc\n",
    "    oof_test['knn'] = preds_knn\n",
    "    oof_test['lr'] = preds_lr\n",
    "\n",
    "    print('nusvc', roc_auc_score(train_df['target'], oof_nusvc))\n",
    "    print('nusvc2', roc_auc_score(train_df['target'], oof_nusvc2))\n",
    "    print('qda', roc_auc_score(train_df['target'], oof_qda))\n",
    "    print('svc', roc_auc_score(train_df['target'], oof_svc))\n",
    "    print('knn', roc_auc_score(train_df['target'], oof_knn))\n",
    "    print('knn', roc_auc_score(train_df['target'], oof_lr))\n",
    "    \n",
    "    return oof_train, oof_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oofs_2(random_state):\n",
    "    oof_nusvc = np.zeros(len(train_df))\n",
    "    preds_nusvc = np.zeros(len(test_df))\n",
    "\n",
    "    oof_nusvc2 = np.zeros(len(train_df))\n",
    "    preds_nusvc2 = np.zeros(len(test_df))\n",
    "\n",
    "    oof_qda = np.zeros(len(train_df))\n",
    "    preds_qda = np.zeros(len(test_df))\n",
    "\n",
    "    oof_svc = np.zeros(len(train_df))\n",
    "    preds_svc = np.zeros(len(test_df))\n",
    "    \n",
    "    oof_knn = np.zeros(len(train_df))\n",
    "    preds_knn = np.zeros(len(test_df))\n",
    "\n",
    "    oof_lr = np.zeros(len(train_df))\n",
    "    preds_lr = np.zeros(len(test_df))\n",
    "    \n",
    "    cols = [c for c in train_df.columns if c not in ['id', 'target', 'wheezy-copper-turtle-magic']]\n",
    "\n",
    "    for i in tqdm_notebook(range(512)):\n",
    "\n",
    "        # each magic\n",
    "        train = train_df[train_df['wheezy-copper-turtle-magic'] == i]\n",
    "        test = test_df[test_df['wheezy-copper-turtle-magic'] == i]\n",
    "\n",
    "        # for oof\n",
    "        train_idx_origin = train.index\n",
    "        test_idx_origin = test.index\n",
    "\n",
    "\n",
    "        # start point\n",
    "\n",
    "        # new cols\n",
    "        cols = magic_variance_over2[i]\n",
    "\n",
    "        X_train = train.reset_index(drop=True)[cols].values\n",
    "        y_train = train.reset_index(drop=True).target\n",
    "\n",
    "        X_test = test[cols].values\n",
    "\n",
    "        # vstack\n",
    "        data = np.vstack([X_train, X_test])\n",
    "\n",
    "        # PCA\n",
    "        data = KernelPCA(n_components=len(cols), kernel='cosine', random_state=random_state).fit_transform(data)\n",
    "\n",
    "        # Bad\n",
    "        '''\n",
    "        gmm_pred = np.zeros((len(data), 5))\n",
    "        for j in range(5):\n",
    "            gmm = GMM(n_components=4, random_state=random_state + j, max_iter=1000).fit(data)\n",
    "            gmm_pred[:, j] += gmm.predict(data)\n",
    "        '''\n",
    "            \n",
    "        # original\n",
    "        gmm = GMM(n_components=5, random_state=random_state, max_iter=1000, init_params='random').fit(data)\n",
    "        gmm_pred = gmm.predict_proba(data)\n",
    "        gmm_score = gmm.score_samples(data)\n",
    "        gmm_label = gmm.predict(data)\n",
    "        \n",
    "        hist = hist_model(); hist.fit(data)\n",
    "        hist_pred = hist.predict(data).reshape(-1, 1)\n",
    "\n",
    "        data = np.hstack([data, gmm_pred])\n",
    "        \n",
    "        # HOXI\n",
    "        data = np.hstack([data, gmm_pred])\n",
    "        data = np.hstack([data, gmm_pred])\n",
    "        data = np.hstack([data, gmm_pred])\n",
    "        \n",
    "        # Add Some Features\n",
    "        data = np.hstack([data, gmm_pred])\n",
    "        data = np.hstack([data, hist_pred, gmm_score.reshape(-1, 1)])\n",
    "        data = np.hstack([data, gmm_score.reshape(-1, 1)])\n",
    "        data = np.hstack([data, gmm_score.reshape(-1, 1)])\n",
    "\n",
    "        # STANDARD SCALER\n",
    "        data = StandardScaler().fit_transform(data)\n",
    "\n",
    "        # new train/test\n",
    "        X_train = data[:X_train.shape[0]]\n",
    "        X_test = data[X_train.shape[0]:]\n",
    "\n",
    "        fold = StratifiedKFold(n_splits=5, random_state=random_state)\n",
    "        for tr_idx, val_idx in fold.split(X_train, gmm_label[:X_train.shape[0]]):\n",
    "            \n",
    "            # NuSVC 1\n",
    "            clf = svm.NuSVC(**svnu_params)\n",
    "            clf.fit(X_train[tr_idx], y_train[tr_idx])\n",
    "            oof_nusvc[train_idx_origin[val_idx]] = clf.predict_proba(X_train[val_idx])[:,1]\n",
    "            preds_nusvc[test_idx_origin] += clf.predict_proba(X_test)[:,1] / fold.n_splits\n",
    "\n",
    "            # NuSVC 2\n",
    "            clf = svm.NuSVC(**svnu2_params)\n",
    "            clf.fit(X_train[tr_idx], y_train[tr_idx])\n",
    "            oof_nusvc2[train_idx_origin[val_idx]] = clf.predict_proba(X_train[val_idx])[:,1]\n",
    "            preds_nusvc2[test_idx_origin] += clf.predict_proba(X_test)[:,1] / fold.n_splits\n",
    "\n",
    "\n",
    "            # qda 3\n",
    "            clf = QuadraticDiscriminantAnalysis(reg_param=0.111)\n",
    "            clf.fit(X_train[tr_idx], y_train[tr_idx])\n",
    "            oof_qda[train_idx_origin[val_idx]] = clf.predict_proba(X_train[val_idx])[:,1]\n",
    "            preds_qda[test_idx_origin] += clf.predict_proba(X_test)[:,1] / fold.n_splits\n",
    "\n",
    "            # SVC 4\n",
    "            clf = svm.SVC(**svc_params)\n",
    "            clf.fit(X_train[tr_idx], y_train[tr_idx])\n",
    "            oof_svc[train_idx_origin[val_idx]] = clf.predict_proba(X_train[val_idx])[:,1]\n",
    "            preds_svc[test_idx_origin] += clf.predict_proba(X_test)[:,1] / fold.n_splits\n",
    "            \n",
    "            # knn 8\n",
    "            clf = KNeighborsClassifier(n_neighbors=16)\n",
    "            clf.fit(X_train[tr_idx], y_train[tr_idx])\n",
    "            oof_knn[train_idx_origin[val_idx]] = clf.predict_proba(X_train[val_idx])[:,1]\n",
    "            preds_knn[test_idx_origin] += clf.predict_proba(X_test)[:,1] / fold.n_splits   \n",
    "            \n",
    "            # LR 5\n",
    "            clf = linear_model.LogisticRegression(**lr_params)\n",
    "            clf.fit(X_train[tr_idx], y_train[tr_idx])\n",
    "            oof_lr[train_idx_origin[val_idx]] = clf.predict_proba(X_train[val_idx])[:,1]\n",
    "            preds_lr[test_idx_origin] += clf.predict_proba(X_test)[:,1] / fold.n_splits\n",
    "            \n",
    "    oof_train = pd.DataFrame()\n",
    "\n",
    "    oof_train['nusvc'] = oof_nusvc\n",
    "    oof_train['nusvc2'] = oof_nusvc2\n",
    "    oof_train['qda'] = oof_qda\n",
    "    oof_train['svc'] = oof_svc\n",
    "    oof_train['knn'] = oof_knn\n",
    "    oof_train['lr'] = oof_lr\n",
    "    \n",
    "    oof_test = pd.DataFrame()\n",
    "\n",
    "    oof_test['nusvc'] = preds_nusvc\n",
    "    oof_test['nusvc2'] = preds_nusvc2\n",
    "    oof_test['qda'] = preds_qda\n",
    "    oof_test['svc'] = preds_svc\n",
    "    oof_test['knn'] = preds_knn\n",
    "    oof_test['lr'] = preds_lr\n",
    "\n",
    "    print('nusvc', roc_auc_score(train_df['target'], oof_nusvc))\n",
    "    print('nusvc2', roc_auc_score(train_df['target'], oof_nusvc2))\n",
    "    print('qda', roc_auc_score(train_df['target'], oof_qda))\n",
    "    print('svc', roc_auc_score(train_df['target'], oof_svc))\n",
    "    print('knn', roc_auc_score(train_df['target'], oof_knn))\n",
    "    print('knn', roc_auc_score(train_df['target'], oof_lr))\n",
    "    \n",
    "    return oof_train, oof_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07603955880d40a2bd5c63540b086f6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=512), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "nusvc 0.9697681160039973\n",
      "nusvc2 0.9684564916066039\n",
      "qda 0.9719152263852826\n",
      "svc 0.9695333568638665\n",
      "knn 0.9656555049265043\n",
      "knn 0.9437276883758653\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5c2ede509d04e788fbc7c84f25ff0e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=512), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "nusvc 0.9614789041171355\n",
      "nusvc2 0.9613788658787864\n",
      "qda 0.9693820788186868\n",
      "svc 0.9608921224056672\n",
      "knn 0.951323392629666\n",
      "knn 0.9265849986371107\n"
     ]
    }
   ],
   "source": [
    "oof_train_1, oof_test_1 = get_oofs(42)\n",
    "oof_train_4, oof_test_4 = get_oofs_2(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble 0.9738703857899418\n"
     ]
    }
   ],
   "source": [
    "x_train_second_layer = oof_train_1  + oof_train_4\n",
    "x_test_second_layer = oof_test_1  + oof_test_4\n",
    "print('Ensemble', roc_auc_score(train_df['target'], x_train_second_layer.mean(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 SEED 수정 된 거로 바꿔야 함. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('../input/sample_submission.csv')\n",
    "submit[\"target\"] = x_test_second_layer.mean(1)\n",
    "submit.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
