{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from scipy.stats import boxcox\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from itertools import product\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from subprocess import check_output\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from scipy.stats import rankdata\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_path = 'ensemble/oof'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_all_result(path,key,df):\n",
    "    file_list = []\n",
    "    file_path_list=[]\n",
    "    try:\n",
    "        for file in listdir(ensemble_path):\n",
    "\n",
    "            if file.find('.csv')==-1:\n",
    "                continue\n",
    "\n",
    "            print(file)    \n",
    "            file_list.append(file)\n",
    "            file_path = join(ensemble_path,file)\n",
    "            file_path_list.append(file_path)\n",
    "            temp = pd.read_csv(file_path)\n",
    "            #predict_list.append(temp[LABELS].values)\n",
    "            if df.empty == True:\n",
    "                print(\"empty\")\n",
    "                df = df.append(temp)\n",
    "            else:\n",
    "                print(\"in\")\n",
    "                df = df.merge(temp,on=key)\n",
    "    except BaseException as e:\n",
    "        print(\"exception\")\n",
    "        print(e)\n",
    "    finally:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyeonwoo_test_oof.csv\n",
      "empty\n",
      "hyeonwoo_test_oof_auc.csv\n",
      "in\n",
      "hyeonwoo_test_oof_cat_auc.csv\n",
      "in\n",
      "hyeonwoo_test_oof_xgb_auc.csv\n",
      "in\n",
      "hyeonwoo_train_oof.csv\n",
      "in\n",
      "hyeonwoo_train_oof_auc.csv\n",
      "in\n",
      "hyeonwoo_train_oof_cat_auc.csv\n",
      "in\n",
      "hyeonwoo_train_oof_xgb_auc.csv\n",
      "in\n",
      "test_oof_augmented_2500_auc_0.9057314966569757_logloss__function log_loss at 0x7f9ab3285bf8__v1.csv\n",
      "in\n",
      "test_oof_augmented_2500_cv_auc_0.9053867482566532_logloss_0.043834212933958186_v2.csv\n",
      "empty\n",
      "exception\n",
      "Plan shapes are not aligned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "predict_list = []\n",
    "data = pd.DataFrame()\n",
    "data = merge_all_result(ensemble_path,'card_id',data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if 'target' in data.columns:\n",
    "    devide_val = data.shape[1]-1\n",
    "    data['target'] = data['target_x'].sum(axis=1) + data['target_x'].sum(axis=1) + data['target']\n",
    "    data['target'] = data['target']/devide_val\n",
    "    del data['target_x'], data['target_y']\n",
    "else:\n",
    "    devide_val = data.shape[1]-1\n",
    "    data['target'] = data['target_x'].sum(axis=1) + data['target_x'].sum(axis=1)\n",
    "    data['target'] = data['target']/devide_val\n",
    "    del data['target_x'], data['target_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.loc[data['card_id']=='C_ID_944c62886f','target'] = -33.21928095"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123623, 2)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 2)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data['target']<-30].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('under_650_result_blending.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_correlation(base_df,target):\n",
    "    \n",
    "    source = base_df.copy()\n",
    "    source = source.merge(target,on='card_id')\n",
    "    corr_df = source.corr()\n",
    "    \n",
    "    corr1 = corr_df.ix['target_x']['target_y']\n",
    "    del corr_df,source\n",
    "    return corr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_same_listing_id(source,target):\n",
    "    return 1 if np.sum(source['card_id'] - target['card_id']) == 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_base_file = '20190225_174621_submission_blend_blend.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20190214_154826_submission_blend_blend.csv\n",
      "ensemble/test6\\20190214_154826_submission_blend_blend.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20190214_154826_submission_blend_blend.csv 0.9933586346809608\n",
      "\n",
      "20190215_235228_submission_blend_blend.csv\n",
      "ensemble/test6\\20190215_235228_submission_blend_blend.csv\n",
      "20190215_235228_submission_blend_blend.csv 0.992778502303612\n",
      "\n",
      "20190217_090058_submission_blend_blend.csv\n",
      "ensemble/test6\\20190217_090058_submission_blend_blend.csv\n",
      "20190217_090058_submission_blend_blend.csv 0.9940342181845591\n",
      "\n",
      "20190218_185933_submission_blend_blend.csv\n",
      "ensemble/test6\\20190218_185933_submission_blend_blend.csv\n",
      "20190218_185933_submission_blend_blend.csv 0.9936965340661271\n",
      "\n",
      "20190221_155851_submission_blend_blend.csv\n",
      "ensemble/test6\\20190221_155851_submission_blend_blend.csv\n",
      "20190221_155851_submission_blend_blend.csv 0.9939540708975336\n",
      "\n",
      "20190222_143608_submission_blend_blend.csv\n",
      "ensemble/test6\\20190222_143608_submission_blend_blend.csv\n",
      "20190222_143608_submission_blend_blend.csv 0.9939191313377468\n",
      "\n",
      "20190222_144911_submission_blend_blend.csv\n",
      "ensemble/test6\\20190222_144911_submission_blend_blend.csv\n",
      "20190222_144911_submission_blend_blend.csv 0.9945864300506005\n",
      "\n",
      "20190223_170816_submission_blend_blend.csv\n",
      "ensemble/test6\\20190223_170816_submission_blend_blend.csv\n",
      "20190223_170816_submission_blend_blend.csv 0.9934268047653007\n",
      "\n",
      "20190224_020616_submission_blend_blend.csv\n",
      "ensemble/test6\\20190224_020616_submission_blend_blend.csv\n",
      "20190224_020616_submission_blend_blend.csv 0.9999334897525404\n",
      "\n",
      "20190224_142652_submission_blend_blend.csv\n",
      "ensemble/test6\\20190224_142652_submission_blend_blend.csv\n",
      "20190224_142652_submission_blend_blend.csv 0.9999334897525404\n",
      "\n",
      "20190225_174621_submission_blend_blend.csv\n",
      "ensemble/test6\\20190225_174621_submission_blend_blend.csv\n",
      "20190225_174621_submission_blend_blend.csv 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_list = []\n",
    "file_path_list=[]\n",
    "base_df = pd.read_csv(join(ensemble_path,ensemble_base_file))\n",
    "corr_dict = dict()\n",
    "try:\n",
    "    for file in listdir(ensemble_path):\n",
    "        \n",
    "        if file.find('.csv')==-1:\n",
    "            continue\n",
    "            \n",
    "        print(file)    \n",
    "        file_list.append(file)\n",
    "        file_path = join(ensemble_path,file)\n",
    "        file_path_list.append(file_path)\n",
    "        print(file_path)\n",
    "        temp = pd.read_csv(file_path)\n",
    "\n",
    "        #if is_same_listing_id(base_df,temp) == 0:    \n",
    "        #    print('error')\n",
    "        #    continue\n",
    "\n",
    "        c = calculate_correlation(base_df,temp)\n",
    "        corr_dict[file]=c\n",
    "        print(file,c)\n",
    "        print(\"\")\n",
    "        #if df.empty == True:\n",
    "        #    print(\"empty\")\n",
    "        #    df = df.append(temp)\n",
    "        #else:\n",
    "        #    print(\"in\")\n",
    "        #    df = df.merge(temp,on='listing_id')\n",
    "except:\n",
    "    print(\"exception\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
