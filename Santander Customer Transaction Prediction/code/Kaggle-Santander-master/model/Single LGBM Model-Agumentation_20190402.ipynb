{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T08:08:56.792621Z",
     "start_time": "2019-04-06T08:08:54.703103Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "from datetime import datetime, timedelta,date\n",
    "import warnings\n",
    "import itertools\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from sklearn.random_projection import SparseRandomProjection,johnson_lindenstrauss_min_dim\n",
    "from sklearn.decomposition import PCA, FastICA,NMF,LatentDirichletAllocation,IncrementalPCA,MiniBatchSparsePCA\n",
    "from sklearn.decomposition import TruncatedSVD,FactorAnalysis,KernelPCA\n",
    "\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, log_loss\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "from scipy.stats import ks_2samp\n",
    "from functools import wraps\n",
    "import functools\n",
    "#settings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T08:08:58.686384Z",
     "start_time": "2019-04-06T08:08:58.656442Z"
    }
   },
   "outputs": [],
   "source": [
    "def time_decorator(func):\n",
    "    \n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        print(\"\\nStartTime: \", datetime.now() + timedelta(hours=9))\n",
    "        start_time = time.time()\n",
    "        \n",
    "        df = func(*args, **kwargs)\n",
    "        \n",
    "        print(\"EndTime: \", datetime.now() + timedelta(hours=9))  \n",
    "        print(\"TotalTime: \", time.time() - start_time)\n",
    "        return df\n",
    "        \n",
    "    return wrapper\n",
    "\n",
    "class SklearnWrapper(object):\n",
    "    def __init__(self, clf, params=None, **kwargs):\n",
    "        \"\"\"\n",
    "        params['random_state'] = kwargs.get('seed', 0)\n",
    "        self.clf = clf(**params)\n",
    "        self.is_classification_problem = True\n",
    "        \"\"\"\n",
    "        if 'random_state' in params:\n",
    "            params['random_state'] = kwargs.get('seed', 0)\n",
    "        self.clf = clf(**params)\n",
    "        self.is_classification_problem = True\n",
    "    @time_decorator\n",
    "    def train(self, x_train, y_train, x_cross=None, y_cross=None):\n",
    "        if len(np.unique(y_train)) > 30:\n",
    "            self.is_classification_problem = False\n",
    "            \n",
    "        self.clf.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        if self.is_classification_problem is True:\n",
    "            return self.clf.predict_proba(x)[:,1]\n",
    "        else:\n",
    "            return self.clf.predict(x)\n",
    "    \n",
    "\n",
    "class CatboostWrapper(object):\n",
    "    def __init__(self, params=None, **kwargs):\n",
    "        \"\"\"\n",
    "        seed\n",
    "        num_rounds\n",
    "        ealry_stopping\n",
    "        eval_function\n",
    "        verbose_eval\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if params is None:\n",
    "                raise(\"Parameter를 입력하세요!!\")\n",
    "            self.param = params\n",
    "            seed = kwargs.get('seed', None)\n",
    "            \n",
    "            if seed is not None:\n",
    "                self.param['random_seed'] = seed\n",
    "                \n",
    "            num_rounds = kwargs.get('num_rounds', None)\n",
    "            if num_rounds is not None:\n",
    "                self.param['num_boost_round'] = num_rounds\n",
    "            \n",
    "            early_stopping = kwargs.get('ealry_stopping', None)\n",
    "            if early_stopping is not None:\n",
    "                self.param['early_stopping_rounds'] = early_stopping\n",
    "            \n",
    "            eval_function = kwargs.get('eval_function', None)\n",
    "            if eval_function is not None:\n",
    "                self.param['eval_metric'] = eval_function\n",
    "            \n",
    "            verbose_eval = kwargs.get('verbose_eval', 100)\n",
    "            if verbose_eval is not None:\n",
    "                self.param['verbose'] = verbose_eval\n",
    "                \n",
    "            self.best_round = 0\n",
    "            \n",
    "            self.is_classification_problem = True\n",
    "        except BaseException as e:\n",
    "            print(e)\n",
    "            \n",
    "    @time_decorator\n",
    "    def train(self, x_train, y_train, x_cross=None, y_cross=None):\n",
    "        \"\"\"\n",
    "        x_cross or y_cross is None\n",
    "        -> model train limted num_rounds\n",
    "        \n",
    "        x_cross and y_cross is Not None\n",
    "        -> model train using validation set\n",
    "        \"\"\"\n",
    "        if isinstance(y_train, pd.DataFrame) is True:\n",
    "            y_train = y_train[y_train.columns[0]]\n",
    "            if y_cross is not None:\n",
    "                y_cross = y_cross[y_cross.columns[0]]\n",
    "\n",
    "        if x_cross is None:\n",
    "            train_round = self.clf.tree_count_\n",
    "            if self.best_round > 0:\n",
    "                train_round = self.best_round\n",
    "            \n",
    "            self.param['iterations'] = train_round\n",
    "            self.clf = cb.CatBoostClassifier(**self.param)\n",
    "            self.clf.fit(x_train, y_train, use_best_model=True)\n",
    "        else:\n",
    "            self.clf = cb.CatBoostClassifier(**self.param)\n",
    "            self.clf.fit(x_train, y_train,\n",
    "                         eval_set=[(x_cross, y_cross)],\n",
    "                         use_best_model=True)\n",
    "            self.best_round = max(self.best_round, self.clf.tree_count_)\n",
    "            \n",
    "        gc.collect()\n",
    "    \n",
    "    def predict(self, x):\n",
    "        if self.is_classification_problem is True:\n",
    "            return self.clf.predict_proba(x)[:,1]\n",
    "        else:\n",
    "            return self.clf.predict(x)\n",
    "        \n",
    "    def get_params(self):\n",
    "        return self.param\n",
    "    \n",
    "    \n",
    "class XgbWrapper(object):\n",
    "    def __init__(self, params=None, **kwargs):\n",
    "        self.param = params\n",
    "        self.param['seed'] = kwargs.get('seed', 0)\n",
    "        self.num_rounds = kwargs.get('num_rounds', 1000)\n",
    "        self.early_stopping = kwargs.get('ealry_stopping', 100)\n",
    "\n",
    "        self.eval_function = kwargs.get('eval_function', None)\n",
    "        self.verbose_eval = kwargs.get('verbose_eval', 100)\n",
    "        self.best_round = 0\n",
    "    \n",
    "    @time_decorator\n",
    "    def train(self, x_train, y_train, x_cross=None, y_cross=None):\n",
    "        need_cross_validation = True\n",
    "        \n",
    "        if isinstance(y_train, pd.DataFrame) is True:\n",
    "            y_train = y_train[y_train.columns[0]]\n",
    "            if y_cross is not None:\n",
    "                y_cross = y_cross[y_cross.columns[0]]\n",
    "                \n",
    "\n",
    "        if x_cross is None:\n",
    "            dtrain = xgb.DMatrix(x_train, label=y_train, silent= True)\n",
    "            train_round = self.best_round\n",
    "            if self.best_round == 0:\n",
    "                train_round = self.num_rounds\n",
    "            \n",
    "            print(train_round)\n",
    "            self.clf = xgb.train(self.param, dtrain, train_round)\n",
    "            del dtrain\n",
    "        else:\n",
    "            dtrain = xgb.DMatrix(x_train, label=y_train, silent=True)\n",
    "            dvalid = xgb.DMatrix(x_cross, label=y_cross, silent=True)\n",
    "            watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "\n",
    "            self.clf = xgb.train(self.param, dtrain, self.num_rounds, watchlist, feval=self.eval_function,\n",
    "                                 early_stopping_rounds=self.early_stopping,\n",
    "                                 verbose_eval=self.verbose_eval)\n",
    "            self.best_round = max(self.best_round, self.clf.best_iteration)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(xgb.DMatrix(x), ntree_limit=self.best_round)\n",
    "\n",
    "    def get_params(self):\n",
    "        return self.param\n",
    "    \n",
    "    \n",
    "class LgbmWrapper(object):\n",
    "    def __init__(self, params=None, **kwargs):\n",
    "        self.param = params\n",
    "        self.param['seed'] = kwargs.get('seed', 0)\n",
    "        self.num_rounds = kwargs.get('num_rounds', 1000)\n",
    "        self.early_stopping = kwargs.get('ealry_stopping', 100)\n",
    "\n",
    "        self.eval_function = kwargs.get('eval_function', None)\n",
    "        self.verbose_eval = kwargs.get('verbose_eval', 100)\n",
    "        self.best_round = 0\n",
    "        \n",
    "    @time_decorator\n",
    "    def train(self, x_train, y_train, x_cross=None, y_cross=None):\n",
    "        \"\"\"\n",
    "        x_cross or y_cross is None\n",
    "        -> model train limted num_rounds\n",
    "        \n",
    "        x_cross and y_cross is Not None\n",
    "        -> model train using validation set\n",
    "        \"\"\"\n",
    "        if isinstance(y_train, pd.DataFrame) is True:\n",
    "            y_train = y_train[y_train.columns[0]]\n",
    "            if y_cross is not None:\n",
    "                y_cross = y_cross[y_cross.columns[0]]\n",
    "\n",
    "        if x_cross is None:\n",
    "            dtrain = lgb.Dataset(x_train, label=y_train, silent= True)\n",
    "            train_round = self.best_round\n",
    "            if self.best_round == 0:\n",
    "                train_round = self.num_rounds\n",
    "                \n",
    "            self.clf = lgb.train(self.param, train_set=dtrain, num_boost_round=train_round)\n",
    "            del dtrain   \n",
    "        else:\n",
    "            dtrain = lgb.Dataset(x_train, label=y_train, silent=True)\n",
    "            dvalid = lgb.Dataset(x_cross, label=y_cross, silent=True)\n",
    "            self.clf = lgb.train(self.param, train_set=dtrain, num_boost_round=self.num_rounds, valid_sets=[dtrain, dvalid],\n",
    "                                  feval=self.eval_function, early_stopping_rounds=self.early_stopping,\n",
    "                                  verbose_eval=self.verbose_eval)\n",
    "            self.best_round = max(self.best_round, self.clf.best_iteration)\n",
    "            del dtrain, dvalid\n",
    "            \n",
    "        gc.collect()\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x, num_iteration=self.clf.best_iteration)\n",
    "    \n",
    "    def plot_importance(self):\n",
    "        lgb.plot_importance(self.clf, max_num_features=50, height=0.7, figsize=(10,30))\n",
    "        plt.show()\n",
    "        \n",
    "    def get_params(self):\n",
    "        return self.param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T08:08:58.967344Z",
     "start_time": "2019-04-06T08:08:58.953354Z"
    }
   },
   "outputs": [],
   "source": [
    "@time_decorator\n",
    "def get_oof(clf, x_train, y_train, x_test, eval_func, **kwargs):\n",
    "    nfolds = kwargs.get('NFOLDS', 5)\n",
    "    kfold_shuffle = kwargs.get('kfold_shuffle', True)\n",
    "    kfold_random_state = kwargs.get('kfold_random_state', 0)\n",
    "    stratified_kfold_ytrain = kwargs.get('stratifed_kfold_y_value', None)\n",
    "    inner_predict = kwargs.get('inner_predict', False)\n",
    "    ntrain = x_train.shape[0]\n",
    "    ntest = x_test.shape[0]\n",
    "    \n",
    "    kf_split = None\n",
    "    if stratified_kfold_ytrain is None:\n",
    "        kf = KFold(n_splits=nfolds, shuffle=kfold_shuffle, random_state=kfold_random_state)\n",
    "        kf_split = kf.split(x_train)\n",
    "    else:\n",
    "        kf = StratifiedKFold(n_splits=nfolds, shuffle=kfold_shuffle, random_state=kfold_random_state)\n",
    "        kf_split = kf.split(x_train, stratified_kfold_ytrain)\n",
    "        \n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "\n",
    "    cv_sum = 0\n",
    "    \n",
    "    # before running model, print model param\n",
    "    # lightgbm model and xgboost model use get_params()\n",
    "    try:\n",
    "        if clf.clf is not None:\n",
    "            print(clf.clf)\n",
    "    except:\n",
    "        print(clf)\n",
    "        print(clf.get_params())\n",
    "\n",
    "    for i, (train_index, cross_index) in enumerate(kf_split):\n",
    "        x_tr, x_cr = None, None\n",
    "        y_tr, y_cr = None, None\n",
    "        if isinstance(x_train, pd.DataFrame):\n",
    "            x_tr, x_cr = x_train.iloc[train_index], x_train.iloc[cross_index]\n",
    "            y_tr, y_cr = y_train.iloc[train_index], y_train.iloc[cross_index]\n",
    "        else:\n",
    "            x_tr, x_cr = x_train[train_index], x_train[cross_index]\n",
    "            y_tr, y_cr = y_train[train_index], y_train[cross_index]\n",
    "\n",
    "        clf.train(x_tr, y_tr, x_cr, y_cr)\n",
    "        \n",
    "        oof_train[cross_index] = clf.predict(x_cr)\n",
    "        if inner_predict is True:\n",
    "            oof_test += clf.predict(x_test)\n",
    "        \n",
    "        cv_score = eval_func(y_cr, oof_train[cross_index])\n",
    "        \n",
    "        print('Fold %d / ' % (i+1), 'CV-Score: %.6f' % cv_score)\n",
    "        cv_sum = cv_sum + cv_score\n",
    "        \n",
    "        del x_tr, x_cr, y_tr, y_cr\n",
    "        \n",
    "    gc.collect()\n",
    "    \n",
    "    score = cv_sum / nfolds\n",
    "    print(\"Average CV-Score: \", score)\n",
    "    \n",
    "    if inner_predict is True:\n",
    "        oof_test = oof_test/nfolds\n",
    "    else:\n",
    "        # Using All Dataset, retrain\n",
    "        clf.train(x_train, y_train)\n",
    "        oof_test = clf.predict(x_test)\n",
    "\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1), score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T08:08:59.326356Z",
     "start_time": "2019-04-06T08:08:59.298432Z"
    },
    "code_folding": [
     110,
     191
    ]
   },
   "outputs": [],
   "source": [
    "def augment(x,y,t=2):\n",
    "    xs,xn = [],[]\n",
    "    for i in range(t):\n",
    "        mask = y>0\n",
    "        x1 = x[mask].copy()\n",
    "        ids = np.arange(x1.shape[0])\n",
    "        for c in range(200):\n",
    "            np.random.shuffle(ids)\n",
    "            x1[:,c] = x1[ids][:,c]\n",
    "            x1[:,c*2+200] = x1[ids][:,c*2+200]\n",
    "            con_index = (c*2+1)\n",
    "            x1[:,con_index+200] = x1[ids][:,con_index+200]\n",
    "        xs.append(x1)\n",
    "\n",
    "    for i in range(t//2):\n",
    "        mask = y==0\n",
    "        x1 = x[mask].copy()\n",
    "        ids = np.arange(x1.shape[0])\n",
    "        for c in range(200):\n",
    "            np.random.shuffle(ids)\n",
    "            x1[:,c] = x1[ids][:,c]\n",
    "            x1[:,c*2+200] = x1[ids][:,c*2+200]\n",
    "            con_index = (c*2+1)\n",
    "            x1[:,con_index+200] = x1[ids][:,con_index+200]\n",
    "        xn.append(x1)\n",
    "\n",
    "    xs = np.vstack(xs)\n",
    "    xn = np.vstack(xn)\n",
    "    ys = np.ones(xs.shape[0])\n",
    "    yn = np.zeros(xn.shape[0])\n",
    "    x = np.vstack([x,xs,xn])\n",
    "    y = np.concatenate([y,ys,yn])\n",
    "    return x,y\n",
    "\n",
    "@time_decorator\n",
    "def get_oof_agumentation(clf, x_train, y_train, x_test, eval_func, **kwargs):\n",
    "    \"\"\"\n",
    "    nfolds = kwargs.get('NFOLDS', 5)\n",
    "    kfold_shuffle = kwargs.get('kfold_shuffle', True)\n",
    "    kfold_random_state = kwargs.get('kfold_random_state', 0)\n",
    "    stratified_kfold_ytrain = kwargs.get('stratifed_kfold_y_value', None)\n",
    "    inner_predict = kwargs.get('inner_predict', False)\n",
    "    agumentation_number = kwargs.get('agumentation_number', 5)\n",
    "    is_bagging_rank = kwargs.get('is_bagging_rank', False)\n",
    "    \"\"\"\n",
    "    nfolds = kwargs.get('NFOLDS', 5)\n",
    "    kfold_shuffle = kwargs.get('kfold_shuffle', True)\n",
    "    kfold_random_state = kwargs.get('kfold_random_state', 0)\n",
    "    stratified_kfold_ytrain = kwargs.get('stratifed_kfold_y_value', None)\n",
    "    agumentation_number = kwargs.get('agumentation_number', 5)\n",
    "    is_bagging_rank = kwargs.get('is_bagging_rank', False)\n",
    "    \n",
    "    ntrain = x_train.shape[0]\n",
    "    ntest = x_test.shape[0]\n",
    "    \n",
    "    kf_split = None\n",
    "    if stratified_kfold_ytrain is None:\n",
    "        kf = KFold(n_splits=nfolds, shuffle=kfold_shuffle, random_state=kfold_random_state)\n",
    "        kf_split = kf.split(x_train)\n",
    "    else:\n",
    "        kf = StratifiedKFold(n_splits=nfolds, shuffle=kfold_shuffle, random_state=kfold_random_state)\n",
    "        kf_split = kf.split(x_train, stratified_kfold_ytrain)\n",
    "        \n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    \n",
    "    if is_bagging_rank is True:\n",
    "        oof_test = pd.DataFrame()\n",
    "    else:\n",
    "        oof_test = np.zeros((ntest,))\n",
    "    \n",
    "    cv_sum = 0\n",
    "    \n",
    "    # before running model, print model param\n",
    "    # lightgbm model and xgboost model use get_params()\n",
    "    try:\n",
    "        if clf.clf is not None:\n",
    "            print(clf.clf)\n",
    "    except:\n",
    "        print(clf)\n",
    "        print(clf.get_params())\n",
    "\n",
    "    for i, (train_index, cross_index) in enumerate(kf_split):\n",
    "        x_tr, x_cr = None, None\n",
    "        y_tr, y_cr = None, None\n",
    "        if isinstance(x_train, pd.DataFrame):\n",
    "            x_tr, x_cr = x_train.iloc[train_index], x_train.iloc[cross_index]\n",
    "            y_tr, y_cr = y_train.iloc[train_index], y_train.iloc[cross_index]\n",
    "        else:\n",
    "            x_tr, x_cr = x_train[train_index], x_train[cross_index]\n",
    "            y_tr, y_cr = y_train[train_index], y_train[cross_index]\n",
    "        \n",
    "        if is_bagging_rank is True:\n",
    "            aug_valid = pd.DataFrame()\n",
    "            aug_test = pd.DataFrame()\n",
    "        else:\n",
    "            aug_valid, aug_test = 0,0\n",
    "        for aug_index in range(agumentation_number):\n",
    "            print(\"\\nAgumentation - Fold {} Aug {} Start!\".format(i, aug_index))\n",
    "            x_tr_aug, y_tr_aug = augment(x_tr.values, y_tr.values)\n",
    "            clf.train(x_tr_aug, y_tr_aug, x_cr, y_cr)\n",
    "            \n",
    "            aug_valid_pred = clf.predict(x_cr)\n",
    "            aug_test_pred = clf.predict(x_test)\n",
    "            if is_bagging_rank is True:\n",
    "                aug_valid[aug_index] = aug_valid_pred\n",
    "                aug_test[aug_index] = aug_test_pred\n",
    "            else:\n",
    "                aug_valid += aug_valid_pred\n",
    "                aug_test += aug_test_pred\n",
    "                \n",
    "            print(\"\\nAgumentation - Fold {} Aug {} CV Score: {:.6f}\".format(i, aug_index, roc_auc_score(y_cr, aug_valid_pred)))\n",
    "        \n",
    "        if is_bagging_rank is True:\n",
    "            oof_train[cross_index] = (1 - aug_valid.rank(ascending=False).mean(axis=1)/aug_valid.shape[0])\n",
    "            oof_test[i] = (1 - aug_test.rank(ascending=False).mean(axis=1)/aug_test.shape[0])\n",
    "        else:\n",
    "            oof_train[cross_index] = aug_valid/agumentation_number\n",
    "            oof_test += (aug_test/agumentation_number)\n",
    "\n",
    "        cv_score = eval_func(y_cr, oof_train[cross_index])\n",
    "        \n",
    "        print('Fold %d / ' % (i+1), 'CV-Score: %.6f' % cv_score)\n",
    "        cv_sum = cv_sum + cv_score\n",
    "        \n",
    "        del x_tr, x_cr, y_tr, y_cr\n",
    "        \n",
    "    gc.collect()\n",
    "    \n",
    "    score = cv_sum / nfolds\n",
    "    print(\"Average CV-Score: \", score)\n",
    "    print(\"OOF CV-Score: \", eval_func(y_train, oof_train))\n",
    "    \n",
    "    if is_bagging_rank is True:\n",
    "        test_pred = (1 - oof_test.rank(ascending=False).mean(axis=1)/oof_test.shape[0])\n",
    "        test_pred = test_pred.values\n",
    "    else:\n",
    "        test_pred = oof_test/nfolds\n",
    "    \n",
    "    return oof_train.reshape(-1, 1), test_pred.reshape(-1, 1), score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T08:08:59.502946Z",
     "start_time": "2019-04-06T08:08:59.493927Z"
    }
   },
   "outputs": [],
   "source": [
    "@time_decorator\n",
    "def kfold_test(clf, x_train, y_train, eval_func, **kwargs):\n",
    "    nfolds = kwargs.get('NFOLDS', 5)\n",
    "    kfold_shuffle = kwargs.get('kfold_shuffle', True)\n",
    "    kfold_random_state = kwargs.get('kfold_random_sate', 0)\n",
    "    stratified_kfold_ytrain = kwargs.get('stratifed_kfold_y_value', None)\n",
    "    \n",
    "\n",
    "    kf_split = None\n",
    "    if stratified_kfold_ytrain is None:\n",
    "        kf = KFold(n_splits=nfolds, shuffle=kfold_shuffle, random_state=kfold_random_state)\n",
    "        kf_split = kf.split(x_train)\n",
    "    else:\n",
    "        kf = StratifiedKFold(n_splits=nfolds, shuffle=kfold_shuffle, random_state=kfold_random_state)\n",
    "        kf_split = kf.split(x_train, stratified_kfold_ytrain)\n",
    "        \n",
    "    cv_sum = 0\n",
    "    try:\n",
    "        if clf.clf is not None:\n",
    "            print(clf.clf)\n",
    "    except:\n",
    "        print(clf)\n",
    "        print(clf.get_params())\n",
    "\n",
    "    best_rounds = []\n",
    "    ntrain = x_train.shape[0]\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    \n",
    "    for i, (train_index, cross_index) in enumerate(kf_split):\n",
    "        x_tr, x_cr = x_train.iloc[train_index], x_train.iloc[cross_index]\n",
    "        y_tr, y_cr = y_train.iloc[train_index], y_train.iloc[cross_index]\n",
    "\n",
    "        clf.train(x_tr, y_tr, x_cr, y_cr)\n",
    "        \n",
    "        oof_train[cross_index] = clf.predict(x_cr)\n",
    "        cv_score = eval_func(y_cr, oof_train[cross_index])\n",
    "        \n",
    "        print('Fold %d / ' % (i+1), 'CV-Score: %.6f' % cv_score)\n",
    "        cv_sum = cv_sum + cv_score\n",
    "        best_rounds.append(clf.clf.best_iteration)\n",
    "\n",
    "    score = cv_sum / nfolds\n",
    "    print(\"Average CV-Score: \", score)\n",
    "    print(eval_func(y_train, oof_train))\n",
    "    return score, np.max(best_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T08:08:59.707423Z",
     "start_time": "2019-04-06T08:08:59.693469Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_noise(series, noise_level):\n",
    "    return series * (1 + noise_level * np.random.randn(len(series)))\n",
    "\n",
    "def target_encode(trn_series=None, \n",
    "                  tst_series=None, \n",
    "                  target=None, \n",
    "                  min_samples_leaf=1, \n",
    "                  smoothing=1,\n",
    "                  noise_level=0):\n",
    "    \"\"\"\n",
    "    Smoothing is computed like in the following paper by Daniele Micci-Barreca\n",
    "    https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf\n",
    "    trn_series : training categorical feature as a pd.Series\n",
    "    tst_series : test categorical feature as a pd.Series\n",
    "    target : target data as a pd.Series\n",
    "    min_samples_leaf (int) : minimum samples to take category average into account\n",
    "    smoothing (int) : smoothing effect to balance categorical average vs prior  \n",
    "    \"\"\" \n",
    "    assert len(trn_series) == len(target)\n",
    "    assert trn_series.name == tst_series.name\n",
    "    temp = pd.concat([trn_series, target], axis=1)\n",
    "    # Compute target mean \n",
    "    averages = temp.groupby(by=trn_series.name)[target.name].agg([\"mean\", \"count\"])\n",
    "    # Compute smoothing\n",
    "    smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n",
    "    # Apply average function to all target data\n",
    "    prior = target.mean()\n",
    "    # The bigger the count the less full_avg is taken into account\n",
    "    averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n",
    "    averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n",
    "    # Apply averages to trn and tst series\n",
    "    ft_trn_series = pd.merge(\n",
    "        trn_series.to_frame(trn_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=trn_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_trn_series.index = trn_series.index \n",
    "    ft_tst_series = pd.merge(\n",
    "        tst_series.to_frame(tst_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=tst_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_tst_series.index = tst_series.index\n",
    "    return add_noise(ft_trn_series, noise_level), add_noise(ft_tst_series, noise_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T08:09:00.406163Z",
     "start_time": "2019-04-06T08:09:00.402193Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_col(df):\n",
    "    train_columns = [col for col in df.columns if col not in ['ID_code','target']]\n",
    "    print(len(train_columns))\n",
    "    \"\"\"\n",
    "    for col in ['var_7', 'var_10', 'var_17', 'var_27', 'var_30', 'var_38',\n",
    "           'var_39', 'var_41', 'var_96', 'var_100', 'var_103', 'var_126',\n",
    "           'var_136', 'var_158', 'var_161', 'var_185']:\n",
    "        train_columns.remove(col)\n",
    "    \"\"\"\n",
    "    print(len(train_columns))\n",
    "    return train_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T08:09:25.584407Z",
     "start_time": "2019-04-06T08:09:12.690862Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T08:09:26.650476Z",
     "start_time": "2019-04-06T08:09:26.638487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "train_columns = train_col(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T08:09:30.841501Z",
     "start_time": "2019-04-06T08:09:27.706927Z"
    }
   },
   "outputs": [],
   "source": [
    "train[train_columns] = np.round(train[train_columns],4)\n",
    "test[train_columns] = np.round(test[train_columns],4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T08:09:58.597702Z",
     "start_time": "2019-04-06T08:09:58.590706Z"
    }
   },
   "outputs": [],
   "source": [
    "pb_idx = np.load('./data_temp/public_LB.npy')\n",
    "pv_idx = np.load('./data_temp/private_LB.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T08:10:15.999044Z",
     "start_time": "2019-04-06T08:10:15.648982Z"
    }
   },
   "outputs": [],
   "source": [
    "test_pb = test.iloc[pb_idx].sort_index().copy()\n",
    "test_pv = test.iloc[pv_idx].sort_index().copy()\n",
    "\n",
    "test_real = test_pb.append(test_pv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T08:10:36.360490Z",
     "start_time": "2019-04-06T08:10:33.192923Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.concat([train, test_real],sort=False)\n",
    "data = data.reset_index(drop=True)\n",
    "data[train_columns] = np.round(data[train_columns],4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T08:11:58.036680Z",
     "start_time": "2019-04-06T08:10:37.141980Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [01:13<00:00,  1.77it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [00:07<00:00, 26.02it/s]\n"
     ]
    }
   ],
   "source": [
    "unique_df = data[['ID_code']]\n",
    "con_df = data[['ID_code']]\n",
    "for col in tqdm(train_columns):\n",
    "    unique_df[col] = data[col].map(((data[col].value_counts() == 1) * 1).to_dict())\n",
    "    con_df[col] = data[col].map((~(data[col].value_counts() == 1) * 1).to_dict())\n",
    "    \n",
    "for col in tqdm(train_columns):\n",
    "    data[col + '_unique'] = np.around(data[col] * unique_df[col], 4)\n",
    "    data[col + '_con'] = np.around(data[col] * con_df[col], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T08:12:01.254365Z",
     "start_time": "2019-04-06T08:11:58.659286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "600\n"
     ]
    }
   ],
   "source": [
    "train_columns = train_col(data)\n",
    "uniquecol_list = [col for col in train_columns if col.find('unique')!= -1]\n",
    "for col in uniquecol_list:\n",
    "    data.loc[data[col]==0,col]=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T08:12:02.796665Z",
     "start_time": "2019-04-06T08:12:02.108472Z"
    }
   },
   "outputs": [],
   "source": [
    "train = data[~data.target.isna()]\n",
    "test = data[data.target.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T08:12:15.405078Z",
     "start_time": "2019-04-06T08:12:15.399093Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "600\n"
     ]
    }
   ],
   "source": [
    "train_columns = train_col(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T08:12:17.754627Z",
     "start_time": "2019-04-06T08:12:17.165863Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = train.copy()\n",
    "y_train = train['target']\n",
    "x_test = test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-06T08:14:08.622278Z",
     "start_time": "2019-04-06T08:12:24.966128Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "\n",
      "StartTime:  2019-04-07 02:12:25.644318\n",
      "<__main__.LgbmWrapper object at 0x000001E510F97198>\n",
      "{'objective': 'binary', 'metric': 'auc', 'boosting': 'gbdt', 'max_depth': -1, 'num_leaves': 13, 'learning_rate': 0.01, 'bagging_freq': 5, 'bagging_fraction': 0.4, 'feature_fraction': 0.05, 'min_data_in_leaf': 80, 'min_sum_heassian_in_leaf': 10, 'tree_learner': 'serial', 'boost_from_average': 'false', 'nthread': 8, 'bagging_seed': 42, 'verbosity': -1, 'seed': 0}\n",
      "\n",
      "Agumentation - Fold 0 Aug 0 Start!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-bbe4437d5bfa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m                                                                            \u001b[0mNFOLDS\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkfold_random_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m                                                                            \u001b[0mstratifed_kfold_y_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m                                                                            agumentation_number=5 )\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mx_train_second_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlgbm_train_aug3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-fac853f4419b>\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"EndTime: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhours\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-24a0e241dbbd>\u001b[0m in \u001b[0;36mget_oof_agumentation\u001b[1;34m(clf, x_train, y_train, x_test, eval_func, **kwargs)\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maug_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magumentation_number\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nAgumentation - Fold {} Aug {} Start!\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maug_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m             \u001b[0mx_tr_aug\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_tr_aug\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maugment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m             \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_tr_aug\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_tr_aug\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_cr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_cr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-24a0e241dbbd>\u001b[0m in \u001b[0;36maugment\u001b[1;34m(x, y, t)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[0mx1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m             \u001b[0mx1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mcon_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lgbm_param3 = {\n",
    "    \"objective\" : \"binary\",\n",
    "    \"metric\" : \"auc\",\n",
    "    \"boosting\": 'gbdt',\n",
    "    \"max_depth\" : -1,\n",
    "    \"num_leaves\" : 13,\n",
    "    \"learning_rate\" : 0.01,\n",
    "    \"bagging_freq\": 5,\n",
    "    \"bagging_fraction\" : 0.4,\n",
    "    \"feature_fraction\" : 0.05,\n",
    "    \"min_data_in_leaf\": 80,\n",
    "    \"min_sum_heassian_in_leaf\": 10,\n",
    "    \"tree_learner\": \"serial\",\n",
    "    \"boost_from_average\": \"false\",\n",
    "    #\"lambda_l1\" : 5,\n",
    "    #\"lambda_l2\" : 5,\n",
    "    \"nthread\": 8,\n",
    "    \"bagging_seed\" : 42,\n",
    "    \"verbosity\" : -1,\n",
    "    \"seed\": 42\n",
    "}\n",
    "\n",
    "lgbm_model3 = LgbmWrapper(params=lgbm_param3, num_rounds = 50000, ealry_stopping=3500,\n",
    "                                   verbose_eval=1000)\n",
    "\n",
    "print(len(train_columns))\n",
    "lgbm_train_aug3, lgbm_test_aug3, lgbm_cv_score_aug3 = get_oof_agumentation(lgbm_model3, x_train[train_columns], y_train, \n",
    "                                                                           x_test[train_columns], roc_auc_score, \n",
    "                                                                           NFOLDS=5, kfold_random_state=42, \n",
    "                                                                           stratifed_kfold_y_value=y_train, \n",
    "                                                                           agumentation_number=5 )\n",
    "\n",
    "x_train_second_layer = pd.DataFrame(lgbm_train_aug3)\n",
    "x_test_second_layer = pd.DataFrame(lgbm_test_aug3)\n",
    "lgb_train = pd.concat([train['ID_code'], pd.DataFrame(x_train_second_layer)], axis=1)\n",
    "lgb_test = pd.concat([test.reset_index(drop=True)['ID_code'], pd.DataFrame(x_test_second_layer)], axis=1)\n",
    "lgb_train.to_csv(f'input/train_lgb_wonho_prod_cv_{lgbm_cv_score_aug3}.csv', index=False)\n",
    "lgb_test.to_csv(f'input/test_lgb_wonho_prod_cv_{lgbm_cv_score_aug3}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model History"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원호님 unique con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fold 1 /  CV-Score: 0.918565\n",
    "Fold 2 /  CV-Score: 0.918630\n",
    "Fold 3 /  CV-Score: 0.925149\n",
    "Fold 4 /  CV-Score: 0.918599\n",
    "Fold 5 /  CV-Score: 0.916176\n",
    "600\n",
    "Fold 1 /  CV-Score: 0.919139\n",
    "Fold 2 /  CV-Score: 0.919246\n",
    "Fold 3 /  CV-Score: 0.925560\n",
    "Fold 4 /  CV-Score: 0.919683\n",
    "Fold 5 /  CV-Score: 0.917102\n",
    "Average CV-Score:  0.9201459354177967\n",
    "StartTime:  2019-04-02 10:21:24.576633\n",
    "<__main__.LgbmWrapper object at 0x000002684F1127F0>\n",
    "{'objective': 'binary', 'metric': 'auc', 'boosting': 'gbdt', 'max_depth': -1, 'num_leaves': 13, 'learning_rate': 0.01, 'bagging_freq': 5, 'bagging_fraction': 0.4, 'feature_fraction': 0.05, 'min_data_in_leaf': 80, 'min_sum_heassian_in_leaf': 10, 'tree_learner': 'serial', 'boost_from_average': 'false', 'nthread': 44, 'bagging_seed': 42, 'verbosity': -1, 'seed': 0}\n",
    "\n",
    "StartTime:  2019-04-02 10:21:25.040010\n",
    "Training until validation scores don't improve for 3500 rounds.\n",
    "[1000]\ttraining's auc: 0.907899\tvalid_1's auc: 0.891966\n",
    "[2000]\ttraining's auc: 0.925801\tvalid_1's auc: 0.905426\n",
    "[3000]\ttraining's auc: 0.936271\tvalid_1's auc: 0.91154\n",
    "[4000]\ttraining's auc: 0.943512\tvalid_1's auc: 0.914939\n",
    "[5000]\ttraining's auc: 0.949263\tvalid_1's auc: 0.916695\n",
    "[6000]\ttraining's auc: 0.954219\tvalid_1's auc: 0.91764\n",
    "[7000]\ttraining's auc: 0.958745\tvalid_1's auc: 0.918279\n",
    "[8000]\ttraining's auc: 0.962872\tvalid_1's auc: 0.918643\n",
    "[9000]\ttraining's auc: 0.966675\tvalid_1's auc: 0.918858\n",
    "[10000]\ttraining's auc: 0.97014\tvalid_1's auc: 0.91895\n",
    "[11000]\ttraining's auc: 0.973361\tvalid_1's auc: 0.91902\n",
    "[12000]\ttraining's auc: 0.976274\tvalid_1's auc: 0.919015\n",
    "[13000]\ttraining's auc: 0.978945\tvalid_1's auc: 0.919097\n",
    "[14000]\ttraining's auc: 0.981459\tvalid_1's auc: 0.919062\n",
    "[15000]\ttraining's auc: 0.983649\tvalid_1's auc: 0.918996\n",
    "[16000]\ttraining's auc: 0.985654\tvalid_1's auc: 0.918898\n",
    "Early stopping, best iteration is:\n",
    "[12899]\ttraining's auc: 0.97869\tvalid_1's auc: 0.919139\n",
    "EndTime:  2019-04-02 10:25:08.818998\n",
    "TotalTime:  223.77897906303406\n",
    "Fold 1 /  CV-Score: 0.919139\n",
    "\n",
    "StartTime:  2019-04-02 10:25:25.794274\n",
    "Training until validation scores don't improve for 3500 rounds.\n",
    "[1000]\ttraining's auc: 0.907364\tvalid_1's auc: 0.894187\n",
    "[2000]\ttraining's auc: 0.925377\tvalid_1's auc: 0.906872\n",
    "[3000]\ttraining's auc: 0.935924\tvalid_1's auc: 0.912815\n",
    "[4000]\ttraining's auc: 0.943083\tvalid_1's auc: 0.915741\n",
    "[5000]\ttraining's auc: 0.948861\tvalid_1's auc: 0.91722\n",
    "[6000]\ttraining's auc: 0.953989\tvalid_1's auc: 0.918044\n",
    "[7000]\ttraining's auc: 0.958508\tvalid_1's auc: 0.918597\n",
    "[8000]\ttraining's auc: 0.962649\tvalid_1's auc: 0.918907\n",
    "[9000]\ttraining's auc: 0.966461\tvalid_1's auc: 0.919094\n",
    "[10000]\ttraining's auc: 0.970017\tvalid_1's auc: 0.919069\n",
    "[11000]\ttraining's auc: 0.973299\tvalid_1's auc: 0.919179\n",
    "[12000]\ttraining's auc: 0.976237\tvalid_1's auc: 0.919176\n",
    "[13000]\ttraining's auc: 0.978965\tvalid_1's auc: 0.919146\n",
    "[14000]\ttraining's auc: 0.981442\tvalid_1's auc: 0.919074\n",
    "[15000]\ttraining's auc: 0.983648\tvalid_1's auc: 0.919001\n",
    "Early stopping, best iteration is:\n",
    "[12334]\ttraining's auc: 0.977168\tvalid_1's auc: 0.919246\n",
    "EndTime:  2019-04-02 10:28:58.490950\n",
    "TotalTime:  212.69857168197632\n",
    "Fold 2 /  CV-Score: 0.919246\n",
    "\n",
    "StartTime:  2019-04-02 10:29:14.493204\n",
    "Training until validation scores don't improve for 3500 rounds.\n",
    "[1000]\ttraining's auc: 0.906475\tvalid_1's auc: 0.897607\n",
    "[2000]\ttraining's auc: 0.924184\tvalid_1's auc: 0.911543\n",
    "[3000]\ttraining's auc: 0.93475\tvalid_1's auc: 0.918184\n",
    "[4000]\ttraining's auc: 0.942014\tvalid_1's auc: 0.921466\n",
    "[5000]\ttraining's auc: 0.947833\tvalid_1's auc: 0.923241\n",
    "[6000]\ttraining's auc: 0.952986\tvalid_1's auc: 0.92411\n",
    "[7000]\ttraining's auc: 0.957593\tvalid_1's auc: 0.924833\n",
    "[8000]\ttraining's auc: 0.961815\tvalid_1's auc: 0.925197\n",
    "[9000]\ttraining's auc: 0.965722\tvalid_1's auc: 0.925269\n",
    "[10000]\ttraining's auc: 0.969275\tvalid_1's auc: 0.925507\n",
    "[11000]\ttraining's auc: 0.972582\tvalid_1's auc: 0.925415\n",
    "[12000]\ttraining's auc: 0.975625\tvalid_1's auc: 0.925333\n",
    "[13000]\ttraining's auc: 0.978394\tvalid_1's auc: 0.925303\n",
    "Early stopping, best iteration is:\n",
    "[9775]\ttraining's auc: 0.968467\tvalid_1's auc: 0.92556\n",
    "EndTime:  2019-04-02 10:32:12.655822\n",
    "TotalTime:  178.1623387336731\n",
    "Fold 3 /  CV-Score: 0.925560\n",
    "\n",
    "StartTime:  2019-04-02 10:32:26.191818\n",
    "Training until validation scores don't improve for 3500 rounds.\n",
    "[1000]\ttraining's auc: 0.907943\tvalid_1's auc: 0.889386\n",
    "[2000]\ttraining's auc: 0.925719\tvalid_1's auc: 0.903155\n",
    "[3000]\ttraining's auc: 0.936133\tvalid_1's auc: 0.910187\n",
    "[4000]\ttraining's auc: 0.943344\tvalid_1's auc: 0.913659\n",
    "[5000]\ttraining's auc: 0.949066\tvalid_1's auc: 0.915768\n",
    "[6000]\ttraining's auc: 0.954016\tvalid_1's auc: 0.916778\n",
    "[7000]\ttraining's auc: 0.9584\tvalid_1's auc: 0.917794\n",
    "[8000]\ttraining's auc: 0.962452\tvalid_1's auc: 0.918278\n",
    "[9000]\ttraining's auc: 0.966195\tvalid_1's auc: 0.918751\n",
    "[10000]\ttraining's auc: 0.96964\tvalid_1's auc: 0.919113\n",
    "[11000]\ttraining's auc: 0.972922\tvalid_1's auc: 0.91937\n",
    "[12000]\ttraining's auc: 0.975888\tvalid_1's auc: 0.919537\n",
    "[13000]\ttraining's auc: 0.978579\tvalid_1's auc: 0.9196\n",
    "[14000]\ttraining's auc: 0.981051\tvalid_1's auc: 0.919614\n",
    "[15000]\ttraining's auc: 0.983308\tvalid_1's auc: 0.919654\n",
    "[16000]\ttraining's auc: 0.98536\tvalid_1's auc: 0.919641\n",
    "[17000]\ttraining's auc: 0.987254\tvalid_1's auc: 0.919593\n",
    "[18000]\ttraining's auc: 0.988905\tvalid_1's auc: 0.919664\n",
    "Early stopping, best iteration is:\n",
    "[14888]\ttraining's auc: 0.983057\tvalid_1's auc: 0.919683\n",
    "EndTime:  2019-04-02 10:36:29.128058\n",
    "TotalTime:  242.93512678146362\n",
    "Fold 4 /  CV-Score: 0.919683\n",
    "\n",
    "StartTime:  2019-04-02 10:36:48.824477\n",
    "Training until validation scores don't improve for 3500 rounds.\n",
    "[1000]\ttraining's auc: 0.908833\tvalid_1's auc: 0.888716\n",
    "[2000]\ttraining's auc: 0.926489\tvalid_1's auc: 0.901878\n",
    "[3000]\ttraining's auc: 0.936652\tvalid_1's auc: 0.908652\n",
    "[4000]\ttraining's auc: 0.943709\tvalid_1's auc: 0.91198\n",
    "[5000]\ttraining's auc: 0.949327\tvalid_1's auc: 0.913992\n",
    "[6000]\ttraining's auc: 0.954268\tvalid_1's auc: 0.915179\n",
    "[7000]\ttraining's auc: 0.958705\tvalid_1's auc: 0.916008\n",
    "[8000]\ttraining's auc: 0.962833\tvalid_1's auc: 0.916351\n",
    "[9000]\ttraining's auc: 0.966562\tvalid_1's auc: 0.916696\n",
    "[10000]\ttraining's auc: 0.969998\tvalid_1's auc: 0.916923\n",
    "[11000]\ttraining's auc: 0.973243\tvalid_1's auc: 0.916969\n",
    "[12000]\ttraining's auc: 0.976171\tvalid_1's auc: 0.917066\n",
    "[13000]\ttraining's auc: 0.978886\tvalid_1's auc: 0.916995\n",
    "[14000]\ttraining's auc: 0.981385\tvalid_1's auc: 0.916894\n",
    "[15000]\ttraining's auc: 0.983599\tvalid_1's auc: 0.91693\n",
    "Early stopping, best iteration is:\n",
    "[12092]\ttraining's auc: 0.976437\tvalid_1's auc: 0.917102\n",
    "EndTime:  2019-04-02 10:40:16.054344\n",
    "TotalTime:  207.22993779182434\n",
    "Fold 5 /  CV-Score: 0.917102\n",
    "Average CV-Score:  0.9201459354177967\n",
    "EndTime:  2019-04-02 10:40:32.841606\n",
    "TotalTime:  1148.2649710178375"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원호님 피쳐 unique만"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[30822]\ttraining's auc: 0.997212\tvalid_1's auc: 0.912799\n",
    "EndTime:  2019-03-31 00:59:26.279200\n",
    "TotalTime:  444.695020198822\n",
    "Fold 1 /  CV-Score: 0.912799\n",
    "    \n",
    "[33555]\ttraining's auc: 0.998189\tvalid_1's auc: 0.913422\n",
    "EndTime:  2019-03-31 01:08:06.521572\n",
    "TotalTime:  479.79382133483887\n",
    "Fold 2 /  CV-Score: 0.913422\n",
    "    \n",
    "[25323]\ttraining's auc: 0.993383\tvalid_1's auc: 0.919691\n",
    "EndTime:  2019-03-31 01:15:09.857498\n",
    "TotalTime:  378.5974488258362\n",
    "Fold 3 /  CV-Score: 0.919691\n",
    "    \n",
    "[34121]\ttraining's auc: 0.99833\tvalid_1's auc: 0.913545\n",
    "EndTime:  2019-03-31 01:23:58.103107\n",
    "TotalTime:  493.46868228912354\n",
    "Fold 4 /  CV-Score: 0.913545\n",
    "    \n",
    "[31306]\ttraining's auc: 0.997418\tvalid_1's auc: 0.911077\n",
    "EndTime:  2019-03-31 01:32:15.184116\n",
    "TotalTime:  451.7067024707794\n",
    "Fold 5 /  CV-Score: 0.911077\n",
    "Average CV-Score:  0.9141068663032271"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prod 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StartTime:  2019-03-30 15:38:32.118556\n",
    "Training until validation scores don't improve for 3500 rounds.\n",
    "[1000]\ttraining's auc: 0.91178\tvalid_1's auc: 0.90005\n",
    "[2000]\ttraining's auc: 0.920072\tvalid_1's auc: 0.904325\n",
    "[3000]\ttraining's auc: 0.92778\tvalid_1's auc: 0.907221\n",
    "[4000]\ttraining's auc: 0.934812\tvalid_1's auc: 0.909616\n",
    "[5000]\ttraining's auc: 0.94112\tvalid_1's auc: 0.91127\n",
    "[6000]\ttraining's auc: 0.946761\tvalid_1's auc: 0.912517\n",
    "[7000]\ttraining's auc: 0.951762\tvalid_1's auc: 0.913306\n",
    "[8000]\ttraining's auc: 0.956583\tvalid_1's auc: 0.913923\n",
    "[9000]\ttraining's auc: 0.960856\tvalid_1's auc: 0.914531\n",
    "[10000]\ttraining's auc: 0.964858\tvalid_1's auc: 0.914981\n",
    "[11000]\ttraining's auc: 0.968527\tvalid_1's auc: 0.915386\n",
    "[12000]\ttraining's auc: 0.971889\tvalid_1's auc: 0.915638\n",
    "[13000]\ttraining's auc: 0.974987\tvalid_1's auc: 0.915694\n",
    "[14000]\ttraining's auc: 0.977749\tvalid_1's auc: 0.915887\n",
    "[15000]\ttraining's auc: 0.980346\tvalid_1's auc: 0.915779\n",
    "[16000]\ttraining's auc: 0.982714\tvalid_1's auc: 0.91594\n",
    "[17000]\ttraining's auc: 0.984817\tvalid_1's auc: 0.91601\n",
    "[18000]\ttraining's auc: 0.986725\tvalid_1's auc: 0.916106\n",
    "[19000]\ttraining's auc: 0.988511\tvalid_1's auc: 0.916132\n",
    "[20000]\ttraining's auc: 0.990012\tvalid_1's auc: 0.916173\n",
    "[21000]\ttraining's auc: 0.991402\tvalid_1's auc: 0.916199\n",
    "[22000]\ttraining's auc: 0.992592\tvalid_1's auc: 0.916233\n",
    "[23000]\ttraining's auc: 0.993667\tvalid_1's auc: 0.916175\n",
    "[24000]\ttraining's auc: 0.994575\tvalid_1's auc: 0.916167\n",
    "[25000]\ttraining's auc: 0.995425\tvalid_1's auc: 0.916117\n",
    "Early stopping, best iteration is:\n",
    "[21862]\ttraining's auc: 0.99242\tvalid_1's auc: 0.91625\n",
    "EndTime:  2019-03-30 15:44:10.832150\n",
    "TotalTime:  338.71357440948486\n",
    "Fold 1 /  CV-Score: 0.916250\n",
    "    \n",
    "[22909]\ttraining's auc: 0.993488\tvalid_1's auc: 0.916135\n",
    "EndTime:  2019-03-30 15:50:24.560323\n",
    "TotalTime:  342.6836714744568\n",
    "Fold 2 /  CV-Score: 0.916135\n",
    "    \n",
    "[21873]\ttraining's auc: 0.991961\tvalid_1's auc: 0.923999\n",
    "EndTime:  2019-03-30 15:56:29.454804\n",
    "TotalTime:  335.19072675704956\n",
    "Fold 3 /  CV-Score: 0.923999\n",
    "    \n",
    "[29033]\ttraining's auc: 0.997673\tvalid_1's auc: 0.917013\n",
    "EndTime:  2019-03-30 16:04:03.982766\n",
    "TotalTime:  425.92881441116333\n",
    "Fold 4 /  CV-Score: 0.917013\n",
    "    \n",
    "[22344]\ttraining's auc: 0.992814\tvalid_1's auc: 0.913404\n",
    "EndTime:  2019-03-30 16:10:20.605982\n",
    "TotalTime:  338.9884412288666\n",
    "Fold 5 /  CV-Score: 0.913404\n",
    "Average CV-Score:  0.9173603456204831\n",
    "EndTime:  2019-03-30 16:10:49.304071\n",
    "TotalTime:  1937.5096695423126\n",
    "    \n",
    "Average CV-Score:  0.9186659561402918"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-30T17:04:52.527765Z",
     "start_time": "2019-03-30T17:04:51.526014Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train_second_layer = pd.DataFrame(lgbm_train_aug3)\n",
    "x_test_second_layer = pd.DataFrame(lgbm_test_aug3)\n",
    "lgb_train = pd.concat([train['ID_code'], pd.DataFrame(x_train_second_layer)], axis=1)\n",
    "lgb_test = pd.concat([test.reset_index(drop=True)['ID_code'], pd.DataFrame(x_test_second_layer)], axis=1)\n",
    "lgb_train.to_csv(f'input/train_lgb_wonho_prod_cv_{lgbm_cv_score_aug3}.csv', index=False)\n",
    "lgb_test.to_csv(f'input/test_lgb_wonho_prod_cv_{lgbm_cv_score_aug3}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-30T17:04:53.394523Z",
     "start_time": "2019-03-30T17:04:53.235464Z"
    }
   },
   "outputs": [],
   "source": [
    "lgb_test = pd.concat([test.reset_index(drop=True)['ID_code'], pd.DataFrame(x_test_second_layer)], axis=1)\n",
    "lgb_test.columns = ['ID_code','target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-30T17:04:54.280028Z",
     "start_time": "2019-03-30T17:04:54.138980Z"
    }
   },
   "outputs": [],
   "source": [
    "test_temp = pd.read_csv('input/test_lgb_aug_df_v8040q1213_rankbagging_v1_cv_0.901779.csv')\n",
    "test_temp.columns = ['ID_code','target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-30T17:04:55.016260Z",
     "start_time": "2019-03-30T17:04:54.998256Z"
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.concat([test_temp.iloc[syn_index],lgb_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-30T17:04:56.563147Z",
     "start_time": "2019-03-30T17:04:56.370441Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>0.754711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>0.883792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>0.859432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>0.101573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>0.555223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test_5</td>\n",
       "      <td>0.019554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test_6</td>\n",
       "      <td>0.105938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test_7</td>\n",
       "      <td>0.088856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>test_8</td>\n",
       "      <td>0.026151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>test_9</td>\n",
       "      <td>0.138631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>test_10</td>\n",
       "      <td>0.899217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>test_11</td>\n",
       "      <td>0.062125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>test_12</td>\n",
       "      <td>0.573485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>test_13</td>\n",
       "      <td>0.394037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>test_14</td>\n",
       "      <td>0.143144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>test_15</td>\n",
       "      <td>0.021231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>test_16</td>\n",
       "      <td>0.501957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>test_17</td>\n",
       "      <td>0.015885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>test_18</td>\n",
       "      <td>0.048853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>test_19</td>\n",
       "      <td>0.206473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>test_20</td>\n",
       "      <td>0.582242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>test_21</td>\n",
       "      <td>0.029988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>test_22</td>\n",
       "      <td>0.002249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>test_23</td>\n",
       "      <td>0.524923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>test_24</td>\n",
       "      <td>0.001042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>test_25</td>\n",
       "      <td>0.783451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>test_26</td>\n",
       "      <td>0.768996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>test_27</td>\n",
       "      <td>0.298083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>test_28</td>\n",
       "      <td>0.910787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>test_29</td>\n",
       "      <td>0.033642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199970</th>\n",
       "      <td>test_199970</td>\n",
       "      <td>0.315469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199971</th>\n",
       "      <td>test_199971</td>\n",
       "      <td>0.815457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199972</th>\n",
       "      <td>test_199972</td>\n",
       "      <td>0.002721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199973</th>\n",
       "      <td>test_199973</td>\n",
       "      <td>0.007772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199974</th>\n",
       "      <td>test_199974</td>\n",
       "      <td>0.001957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199975</th>\n",
       "      <td>test_199975</td>\n",
       "      <td>0.711871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199976</th>\n",
       "      <td>test_199976</td>\n",
       "      <td>0.254605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199977</th>\n",
       "      <td>test_199977</td>\n",
       "      <td>0.870640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199978</th>\n",
       "      <td>test_199978</td>\n",
       "      <td>0.464106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199979</th>\n",
       "      <td>test_199979</td>\n",
       "      <td>0.745051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199980</th>\n",
       "      <td>test_199980</td>\n",
       "      <td>0.086308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199981</th>\n",
       "      <td>test_199981</td>\n",
       "      <td>0.546751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199982</th>\n",
       "      <td>test_199982</td>\n",
       "      <td>0.008435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199983</th>\n",
       "      <td>test_199983</td>\n",
       "      <td>0.016948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199984</th>\n",
       "      <td>test_199984</td>\n",
       "      <td>0.004713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199985</th>\n",
       "      <td>test_199985</td>\n",
       "      <td>0.033020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199986</th>\n",
       "      <td>test_199986</td>\n",
       "      <td>0.306796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199987</th>\n",
       "      <td>test_199987</td>\n",
       "      <td>0.572607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199988</th>\n",
       "      <td>test_199988</td>\n",
       "      <td>0.243709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199989</th>\n",
       "      <td>test_199989</td>\n",
       "      <td>0.533863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199990</th>\n",
       "      <td>test_199990</td>\n",
       "      <td>0.086071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199991</th>\n",
       "      <td>test_199991</td>\n",
       "      <td>0.098804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199992</th>\n",
       "      <td>test_199992</td>\n",
       "      <td>0.926225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199993</th>\n",
       "      <td>test_199993</td>\n",
       "      <td>0.006700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199994</th>\n",
       "      <td>test_199994</td>\n",
       "      <td>0.728862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>test_199995</td>\n",
       "      <td>0.021142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>test_199996</td>\n",
       "      <td>0.004130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>test_199997</td>\n",
       "      <td>0.077273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>test_199998</td>\n",
       "      <td>0.773428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>test_199999</td>\n",
       "      <td>0.028209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID_code    target\n",
       "0            test_0  0.754711\n",
       "1            test_1  0.883792\n",
       "2            test_2  0.859432\n",
       "3            test_3  0.101573\n",
       "4            test_4  0.555223\n",
       "5            test_5  0.019554\n",
       "6            test_6  0.105938\n",
       "7            test_7  0.088856\n",
       "8            test_8  0.026151\n",
       "9            test_9  0.138631\n",
       "10          test_10  0.899217\n",
       "11          test_11  0.062125\n",
       "12          test_12  0.573485\n",
       "13          test_13  0.394037\n",
       "14          test_14  0.143144\n",
       "15          test_15  0.021231\n",
       "16          test_16  0.501957\n",
       "17          test_17  0.015885\n",
       "18          test_18  0.048853\n",
       "19          test_19  0.206473\n",
       "20          test_20  0.582242\n",
       "21          test_21  0.029988\n",
       "22          test_22  0.002249\n",
       "23          test_23  0.524923\n",
       "24          test_24  0.001042\n",
       "25          test_25  0.783451\n",
       "26          test_26  0.768996\n",
       "27          test_27  0.298083\n",
       "28          test_28  0.910787\n",
       "29          test_29  0.033642\n",
       "...             ...       ...\n",
       "199970  test_199970  0.315469\n",
       "199971  test_199971  0.815457\n",
       "199972  test_199972  0.002721\n",
       "199973  test_199973  0.007772\n",
       "199974  test_199974  0.001957\n",
       "199975  test_199975  0.711871\n",
       "199976  test_199976  0.254605\n",
       "199977  test_199977  0.870640\n",
       "199978  test_199978  0.464106\n",
       "199979  test_199979  0.745051\n",
       "199980  test_199980  0.086308\n",
       "199981  test_199981  0.546751\n",
       "199982  test_199982  0.008435\n",
       "199983  test_199983  0.016948\n",
       "199984  test_199984  0.004713\n",
       "199985  test_199985  0.033020\n",
       "199986  test_199986  0.306796\n",
       "199987  test_199987  0.572607\n",
       "199988  test_199988  0.243709\n",
       "199989  test_199989  0.533863\n",
       "199990  test_199990  0.086071\n",
       "199991  test_199991  0.098804\n",
       "199992  test_199992  0.926225\n",
       "199993  test_199993  0.006700\n",
       "199994  test_199994  0.728862\n",
       "199995  test_199995  0.021142\n",
       "199996  test_199996  0.004130\n",
       "199997  test_199997  0.077273\n",
       "199998  test_199998  0.773428\n",
       "199999  test_199999  0.028209\n",
       "\n",
       "[200000 rows x 2 columns]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.concat([test_temp.iloc[syn_index],lgb_test])\n",
    "submission['Index'] = submission['ID_code'].apply(lambda x: int(x.split('_')[-1]))\n",
    "submission = submission.sort_values(\"Index\").reset_index(drop=True)\n",
    "del submission['Index']\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-30T17:05:02.086295Z",
     "start_time": "2019-03-30T17:05:01.572007Z"
    }
   },
   "outputs": [],
   "source": [
    "submission.to_csv(f'sub_lgb_wonho_prod_cv_{lgbm_cv_score_aug3}.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
